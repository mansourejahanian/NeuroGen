{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import time as time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import chain\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from itertools import zip_longest\n",
    "\n",
    "import src.numpy_utility as pnu\n",
    "from src.plots import display_candidate_loss\n",
    "from src.file_utility import save_stuff, flatten_dict, embed_dict\n",
    "from src.torch_fwrf import get_value\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from visualize import center_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "parser = argparse.ArgumentParser(prog='encoding model', \n",
    "\tdescription='input subject ID and gpu, output saved parameters',\n",
    "\tusage='python fwrf_ROIvoxel_mean.py --subj i --gpu j')\n",
    "\n",
    "# parser.add_argument('--subj', type=int)\n",
    "# parser.add_argument('--gpu', type=int)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "nsd_root = 'Z:/CNAI2/Mansoure_NSD/'\n",
    "stim_root = nsd_root + \"nsd_stimuli/\"\n",
    "beta_root = nsd_root + \"nsd_beta/\"\n",
    "#mask_root = nsd_root + \"mask/ppdata/\"\n",
    "#roi_root = nsd_root + \"freesurfer/\"\n",
    "meanROIbeta_root = nsd_root + \"roiavgbeta/\"\n",
    "\n",
    "exp_design_file = nsd_root + \"experiments/nsd_expdesign.mat\"\n",
    "stim_file       = stim_root + \"nsd_stimuli.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available? True\n",
      "#device: 1\n",
      "device#: 0\n",
      "device name: NVIDIA T400\n",
      "\n",
      "torch: 2.1.2\n",
      "cuda:  12.1\n",
      "Time Stamp: Dec-21-2023_1556\n"
     ]
    }
   ],
   "source": [
    "# set up cuda and parameters\n",
    "\n",
    "# test cuda\n",
    "print(\"Cuda available?\", torch.cuda.is_available())\n",
    "\n",
    "print ('#device:', torch.cuda.device_count())\n",
    "print ('device#:', torch.cuda.current_device())\n",
    "print ('device name:', torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "torch.manual_seed(time.time())\n",
    "#device = torch.device(\"cuda:%d\"%args.gpu) #cuda\n",
    "device = torch.device(\"cuda\") #cuda\n",
    "torch.backends.cudnn.enabled=True\n",
    "\n",
    "print ('\\ntorch:', torch.__version__)\n",
    "print ('cuda: ', torch.version.cuda)\n",
    "\n",
    "subject = 1\n",
    "saveext = \".png\"\n",
    "savearg = {'format':'png', 'dpi': 120, 'facecolor': None}\n",
    "timestamp = time.strftime('%b-%d-%Y_%H%M', time.localtime())\n",
    "model_name = 'dnn_fwrf'\n",
    "\n",
    "root_dir   = os.getcwd() + '/'\n",
    "net_dir    = root_dir + \"net/\" \n",
    "#input_dir  = '/home/styvesg/repo.data/results/nsd/torch_fwrf_full_brain/S%02d/dnn_fwrf_May-10-2020_1814/'\n",
    "output_dir = root_dir + \"output/S%02d/%s_%s/\" % (subject,model_name,timestamp) \n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "print (\"Time Stamp: %s\" % timestamp)\n",
    "\n",
    "exp_design = loadmat(exp_design_file)\n",
    "ordering = exp_design['masterordering'].flatten() - 1 # zero-indexed ordering of indices (matlab-like to python-like)\n",
    "subject_idx  = exp_design['subjectim']\n",
    "\n",
    "#stim_pattern = exp_design['stimpattern']\n",
    "#shared_idx   = exp_design['sharedix']\n",
    "#basic_cnt    = exp_design['basiccnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocessing (73000, 425, 425, 3)\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n",
      "saved stimuli in h5py file\n"
     ]
    }
   ],
   "source": [
    "# do not need to run again\n",
    "image_data_set_all = h5py.File(stim_file, 'r')\n",
    "image_data_all = np.copy(image_data_set_all['imgBrick'])\n",
    "image_data_set_all.close()\n",
    "print('before preprocessing',image_data_all.shape)\n",
    "\n",
    "for k,s_idx in enumerate(subject_idx):\n",
    "    s_image_data = image_data_all[s_idx - 1]\n",
    "    s_image_data = np.transpose(s_image_data, (0,3,1,2))\n",
    "    s_image_data = center_crop(s_image_data, 425, 227)\n",
    "\n",
    "    save_stuff(\"%sS%d_stimuli_%d\"%(stim_root, k+1, 227), {'stimuli': s_image_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "\n",
    "# image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "# image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "# image_data_set.close()\n",
    "\n",
    "# load shared stimuli id\n",
    "# shared_stimuli_id = pd.read_csv(stim_root + 'shared1000.txt', sep='\\t', header=None)\n",
    "\n",
    "# f = h5py.File(stim_file, 'r+')\n",
    "# image_data = np.copy(f['imgBrick'][shared_stimuli_id[0]-1,:,:,:])\n",
    "# f.close()\n",
    "\n",
    "# image_data = image_data.astype(np.float32) / 255\n",
    "\n",
    "\n",
    "# print (image_data.shape)\n",
    "# print (image_data.dtype)\n",
    "# print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n",
    "\n",
    "# image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "# image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "# image_data_set.close()\n",
    "\n",
    "# print (image_data.shape)\n",
    "# print (image_data.dtype)\n",
    "# print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size = 3000 , Training size = 27000\n",
      "(30000,)\n",
      "cudnn: 8801\n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_data_set = h5py.File(stim_root + \"S%d_stimuli_227.h5py\"%subject, 'r')\n",
    "image_data = np.copy(image_data_set['stimuli']).astype(np.float32) / 255.\n",
    "image_data_set.close()\n",
    "\n",
    "print (image_data.shape)\n",
    "print (image_data.dtype)\n",
    "print (np.min(image_data[0]), np.max(image_data[0]))\n",
    "\n",
    "trials = np.array([30000, 30000, 24000, 22500, 30000, 24000, 30000, 22500])\n",
    "data_size = trials[subject-1]\n",
    "ordering_data = ordering[:data_size]\n",
    "shared_mask   = ordering_data<1000  # the first 1000 indices are the shared indices\n",
    "\n",
    "val_size = np.sum(shared_mask)\n",
    "trn_size = data_size - val_size\n",
    "print (\"Validation size =\", val_size, \", Training size =\", trn_size)\n",
    "print(ordering_data.shape)\n",
    "\n",
    "stim_data = image_data[ordering_data]  # reduce to only the samples available thus far\n",
    "\n",
    "trn_stim_data = stim_data[~shared_mask]\n",
    "val_stim_data = stim_data[shared_mask]\n",
    "\n",
    "val_image_data = image_data[:1000]\n",
    "\n",
    "print ('cudnn:', torch.backends.cudnn.version())\n",
    "print ('dtype:', torch.get_default_dtype())\n",
    "#torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beta\n",
    "\n",
    "ROIs = ['OFA', 'FFA1', 'FFA2', 'mTLfaces', 'aTLfaces', 'EBA', 'FBA1', 'FBA2', 'mTLbodies', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA1', 'VWFA2', 'mfswords', 'mTLwords', 'V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
    "#ROIs = ['L_hippocampus', 'L_amygdala', 'R_hippocampus', 'R_amygdala']\n",
    "roi_num = len(ROIs)\n",
    "roi_data = np.zeros([data_size, roi_num])\n",
    "n = 0\n",
    "del_idx = []\n",
    "for roi in ROIs:\n",
    "    roi_data[:,n] = np.genfromtxt(meanROIbeta_root + 'subj%02d/meanbeta_'%subject + roi + '.txt')\n",
    "    if np.isnan(np.sum(roi_data[:,n])):\n",
    "    \tdel_idx.append(n)\n",
    "    n += 1\n",
    "\n",
    "roi_data = np.delete(roi_data, del_idx, axis=1)\n",
    "\n",
    "trn_roi_data = roi_data[~shared_mask]\n",
    "val_roi_data = roi_data[shared_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 64, 27, 27])\n",
      "torch.Size([100, 192, 27, 27])\n",
      "torch.Size([100, 384, 13, 13])\n",
      "torch.Size([100, 256, 13, 13])\n",
      "torch.Size([100, 256, 13, 13])\n",
      "torch.Size([100, 4096, 1, 1])\n",
      "torch.Size([100, 4096, 1, 1])\n",
      "torch.Size([100, 1000, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:05,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0, shape=(100, 64, 27, 27)\n",
      "layer: 1, shape=(100, 192, 27, 27)\n",
      "layer: 2, shape=(100, 384, 13, 13)\n",
      "layer: 3, shape=(100, 256, 13, 13)\n",
      "layer: 4, shape=(100, 256, 13, 13)\n",
      "layer: 5, shape=(100, 512, 1, 1)\n",
      "layer: 6, shape=(100, 512, 1, 1)\n",
      "layer: 7, shape=(100, 512, 1, 1)\n",
      "\n",
      "fmaps: 0, shape=(100, 256, 27, 27)\n",
      "fmaps: 1, shape=(100, 896, 13, 13)\n",
      "fmaps: 2, shape=(100, 1536, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 256, 27, 27])\n",
      "torch.Size([100, 896, 13, 13])\n",
      "torch.Size([100, 1536, 1, 1])\n",
      "candidate count =  875\n",
      "trn_size = 24000 (88.9%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "torch.Size([200, 256, 27, 27])\n",
      "torch.Size([200, 896, 13, 13])\n",
      "torch.Size([200, 1536, 1, 1])\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#_log_act_func = lambda _x: torch.log(1 + torch.abs(_x))*torch.tanh(torch.abs(_x))\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_fwrf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  learn_params_ridge_regression, get_predictions, Torch_fwRF_voxel_block\n\u001b[1;32m---> 42\u001b[0m best_losses, best_lambdas, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_params_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrn_stim_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_roi_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fmaps_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43maperture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maperture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m ([p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params])\n\u001b[0;32m     48\u001b[0m param_batch \u001b[38;5;241m=\u001b[39m [p[:voxel_batch_size] \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params]\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\NSD_fMRI\\NeuroGen\\src\\torch_fwrf.py:203\u001b[0m, in \u001b[0;36mlearn_params_ridge_regression\u001b[1;34m(data, voxels, _fmaps_fn, models, lambdas, aperture, _nonlinearity, zscore, sample_batch_size, voxel_batch_size, holdout_size, shuffle, add_bias)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m#############################################################################        \u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m### Create full model value buffers    \u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m best_models \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)   \n\u001b[0;32m    204\u001b[0m best_lambdas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m    205\u001b[0m best_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, shape\u001b[38;5;241m=\u001b[39m(nv), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\Anaconda3\\envs\\cudatest\\Lib\\site-packages\\numpy\\__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "\n",
    "# load feature maps\n",
    "from torchmodel.models.alexnet import Alexnet_fmaps\n",
    "_fmaps_fn = Alexnet_fmaps().to(device)\n",
    "\n",
    "_x = torch.tensor(image_data[:100]).to(device) # the input variable.\n",
    "_fmaps = _fmaps_fn(_x)\n",
    "for k,_fm in enumerate(_fmaps):\n",
    "    print (_fm.size())\n",
    "\n",
    "from src.torch_feature_space import filter_dnn_feature_maps\n",
    "\n",
    "# I used image_data because the repeats are not relevant\n",
    "_fmaps_fn, lmask, fmask, tuning_masks = filter_dnn_feature_maps(image_data, _fmaps_fn, batch_size=100, fmap_max=512)\n",
    "\n",
    "_x = torch.tensor(image_data[:100]).to(device) # the input variable.\n",
    "_fmaps = _fmaps_fn(_x)\n",
    "for k,_fm in enumerate(_fmaps):\n",
    "    print (_fm.size())\n",
    "\n",
    "from src.rf_grid    import linspace, logspace, model_space, model_space_pyramid\n",
    "from src.torch_fwrf import learn_params_ridge_regression, get_predictions\n",
    "\n",
    "aperture = np.float32(1)\n",
    "nx = ny = 11\n",
    "smin, smax = np.float32(0.04), np.float32(0.4)\n",
    "ns = 8\n",
    "\n",
    "# sharedModel specification is a list of 3 ranges and 3 callable functor. The reason for this is for a future implementation of dynamic mesh refinement.\n",
    "#model_specs = [[(0., aperture*1.1), (0., aperture*1.1), (smin, smax)], [linspace(nx), linspace(ny), logspace(ns)]]\n",
    "#models = model_space(model_specs)\n",
    "models = model_space_pyramid(logspace(ns)(smin, smax), min_spacing=1.4, aperture=1.1*aperture)\n",
    "print ('candidate count = ', len(models))\n",
    "\n",
    "sample_batch_size = 200\n",
    "voxel_batch_size = 500\n",
    "holdout_size = 3000\n",
    "lambdas = np.logspace(3.,7.,9, dtype=np.float32)\n",
    "#_log_act_func = lambda _x: torch.log(1 + torch.abs(_x))*torch.tanh(torch.abs(_x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trn_size = 24000 (88.9%)\n",
      "dtype = <class 'numpy.float32'>\n",
      "device = cuda:0\n",
      "---------------------------------------\n",
      "torch.Size([200, 256, 27, 27])\n",
      "torch.Size([200, 896, 13, 13])\n",
      "torch.Size([200, 1536, 1, 1])\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtorch_fwrf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  learn_params_ridge_regression, get_predictions, Torch_fwRF_voxel_block\n\u001b[1;32m----> 3\u001b[0m best_losses, best_lambdas, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mlearn_params_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrn_stim_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrn_roi_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fmaps_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43maperture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maperture\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_nonlinearity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzscore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoxel_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mholdout_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m ([p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params])\n\u001b[0;32m      9\u001b[0m param_batch \u001b[38;5;241m=\u001b[39m [p[:voxel_batch_size] \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m best_params]\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\NSD_fMRI\\NeuroGen\\src\\torch_fwrf.py:203\u001b[0m, in \u001b[0;36mlearn_params_ridge_regression\u001b[1;34m(data, voxels, _fmaps_fn, models, lambdas, aperture, _nonlinearity, zscore, sample_batch_size, voxel_batch_size, holdout_size, shuffle, add_bias)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m#############################################################################        \u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m### Create full model value buffers    \u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m best_models \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)   \n\u001b[0;32m    204\u001b[0m best_lambdas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(shape\u001b[38;5;241m=\u001b[39m(nv,), fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m    205\u001b[0m best_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, shape\u001b[38;5;241m=\u001b[39m(nv), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\mjahani\\Anaconda3\\envs\\cudatest\\Lib\\site-packages\\numpy\\__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from src.torch_fwrf import  learn_params_ridge_regression, get_predictions, Torch_fwRF_voxel_block\n",
    "\n",
    "best_losses, best_lambdas, best_params = learn_params_ridge_regression(\n",
    "    trn_stim_data, trn_roi_data, _fmaps_fn, models, lambdas, \\\n",
    "    aperture=aperture, _nonlinearity=None, zscore=True, sample_batch_size=sample_batch_size, \\\n",
    "    voxel_batch_size=voxel_batch_size, holdout_size=holdout_size, shuffle=False, add_bias=True)\n",
    "\n",
    "print ([p.shape if p is not None else None for p in best_params])\n",
    "param_batch = [p[:voxel_batch_size] if p is not None else None for p in best_params]\n",
    "_fwrf_fn = Torch_fwRF_voxel_block(_fmaps_fn, param_batch, _nonlinearity=None, input_shape=image_data.shape, aperture=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "voxel_pred = get_predictions(val_image_data, _fmaps_fn, _fwrf_fn, best_params, sample_batch_size=sample_batch_size)\n",
    "\n",
    "val_voxel_pred = voxel_pred[ordering[:data_size][shared_mask]]\n",
    "val_cc  = np.zeros(shape=(val_voxel_pred.shape[1]), dtype=fpX)\n",
    "for v in tqdm(range(val_voxel_pred.shape[1])):    \n",
    "    val_cc[v] = np.corrcoef(val_roi_data[:,v], val_voxel_pred[:,v])[0,1]  \n",
    "val_cc = np.nan_to_num(val_cc)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "model_params = {\n",
    "    'lmask': lmask,\n",
    "    'fmask': fmask,\n",
    "    'tuning_masks': tuning_masks,\n",
    "    'aperture': aperture,\n",
    "    #'voxel_mask': voxel_mask,\n",
    "    #'brain_nii_shape': np.array(brain_nii_shape),\n",
    "    'val_size': val_size,\n",
    "    'trn_size': trn_size,\n",
    "    'shared_mask': shared_mask,\n",
    "    'image_order': ordering_data,\n",
    "    #'voxel_index': voxel_idx,\n",
    "    #'voxel_roi': voxel_roi,\n",
    "    'params': best_params,\n",
    "    'lambdas': lambdas, \n",
    "    'best_lambdas': best_lambdas,\n",
    "    'val_cc': val_cc,\n",
    "    }\n",
    "\n",
    "print (timestamp)\n",
    "save_stuff(output_dir + \"model_params\", flatten_dict(model_params))\n",
    "\n",
    "ROIs_label = ['OFA', 'FFA1', 'FFA2', 'mTL \\n faces', 'aTL \\n faces', 'EBA', 'FBA1', 'FBA2', 'mTL \\n bodies', 'OPA', 'PPA', 'RSC', 'OWFA', 'VWFA1', 'VWFA2', 'mfs \\n words', 'mTL \\n words', 'V1v', 'V1d', 'V2v', 'V2d', 'V3v', 'V3d', 'hV4']\n",
    "#ROIs_label = ['L_hippocampus', 'L_amygdala', 'R_hippocampus', 'R_amygdala']\n",
    "ROIs_label = np.delete(ROIs_label,del_idx) \n",
    "plt.figure(figsize=(16,6))\n",
    "plt.bar(ROIs_label,val_cc)\n",
    "plt.savefig(output_dir + 'acc.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Memorability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
